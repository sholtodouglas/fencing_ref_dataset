{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d7d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f40599dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 16\n",
    "input_shape = (15, 20, 1)\n",
    "\n",
    "npz = np.load('classifierdata3.npz')\n",
    "x_train, y_train = np.array(npz['data']), npz['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7418c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (248, 15, 20, 1)\n",
      "248 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9c6d94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 13, 18, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                6160      \n",
      "=================================================================\n",
      "Total params: 24,976\n",
      "Trainable params: 24,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a29b9937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "4/4 [==============================] - 1s 56ms/step - loss: 2.7619 - accuracy: 0.0468 - val_loss: 2.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.6899 - accuracy: 0.1277 - val_loss: 2.6857 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.6003 - accuracy: 0.2383 - val_loss: 2.6107 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.5422 - accuracy: 0.2511 - val_loss: 2.5968 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.4638 - accuracy: 0.2596 - val_loss: 2.5238 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3704 - accuracy: 0.2809 - val_loss: 2.4752 - val_accuracy: 0.2308\n",
      "Epoch 7/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2974 - accuracy: 0.3277 - val_loss: 2.4279 - val_accuracy: 0.2308\n",
      "Epoch 8/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1635 - accuracy: 0.4043 - val_loss: 2.3872 - val_accuracy: 0.2308\n",
      "Epoch 9/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.0712 - accuracy: 0.4809 - val_loss: 2.3202 - val_accuracy: 0.2308\n",
      "Epoch 10/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.9065 - accuracy: 0.5404 - val_loss: 2.2263 - val_accuracy: 0.2308\n",
      "Epoch 11/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.8021 - accuracy: 0.5745 - val_loss: 2.0298 - val_accuracy: 0.2308\n",
      "Epoch 12/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.6716 - accuracy: 0.6426 - val_loss: 1.8002 - val_accuracy: 0.6154\n",
      "Epoch 13/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4929 - accuracy: 0.7021 - val_loss: 1.6430 - val_accuracy: 1.0000\n",
      "Epoch 14/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3791 - accuracy: 0.7149 - val_loss: 1.5495 - val_accuracy: 1.0000\n",
      "Epoch 15/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2279 - accuracy: 0.7957 - val_loss: 1.5085 - val_accuracy: 0.6923\n",
      "Epoch 16/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0452 - accuracy: 0.8426 - val_loss: 1.2408 - val_accuracy: 1.0000\n",
      "Epoch 17/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9702 - accuracy: 0.8468 - val_loss: 1.0512 - val_accuracy: 1.0000\n",
      "Epoch 18/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8014 - accuracy: 0.8894 - val_loss: 0.9889 - val_accuracy: 1.0000\n",
      "Epoch 19/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6502 - accuracy: 0.8979 - val_loss: 1.0064 - val_accuracy: 1.0000\n",
      "Epoch 20/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6537 - accuracy: 0.8936 - val_loss: 0.8847 - val_accuracy: 1.0000\n",
      "Epoch 21/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4996 - accuracy: 0.9532 - val_loss: 0.7197 - val_accuracy: 1.0000\n",
      "Epoch 22/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4246 - accuracy: 0.9660 - val_loss: 0.6438 - val_accuracy: 1.0000\n",
      "Epoch 23/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4138 - accuracy: 0.9404 - val_loss: 0.6603 - val_accuracy: 1.0000\n",
      "Epoch 24/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3730 - accuracy: 0.9702 - val_loss: 0.6619 - val_accuracy: 1.0000\n",
      "Epoch 25/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2701 - accuracy: 0.9702 - val_loss: 0.6501 - val_accuracy: 1.0000\n",
      "Epoch 26/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2474 - accuracy: 0.9745 - val_loss: 0.5145 - val_accuracy: 1.0000\n",
      "Epoch 27/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2186 - accuracy: 0.9830 - val_loss: 0.4398 - val_accuracy: 1.0000\n",
      "Epoch 28/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2075 - accuracy: 0.9787 - val_loss: 0.4166 - val_accuracy: 1.0000\n",
      "Epoch 29/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1779 - accuracy: 0.9957 - val_loss: 0.3977 - val_accuracy: 1.0000\n",
      "Epoch 30/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1630 - accuracy: 0.9872 - val_loss: 0.3729 - val_accuracy: 1.0000\n",
      "Epoch 31/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1373 - accuracy: 0.9915 - val_loss: 0.3297 - val_accuracy: 1.0000\n",
      "Epoch 32/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1314 - accuracy: 0.9915 - val_loss: 0.3272 - val_accuracy: 1.0000\n",
      "Epoch 33/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1055 - accuracy: 0.9957 - val_loss: 0.2856 - val_accuracy: 1.0000\n",
      "Epoch 34/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0957 - accuracy: 0.9915 - val_loss: 0.2607 - val_accuracy: 1.0000\n",
      "Epoch 35/1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0847 - accuracy: 0.9957 - val_loss: 0.2540 - val_accuracy: 1.0000\n",
      "Epoch 36/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0767 - accuracy: 0.9915 - val_loss: 0.2333 - val_accuracy: 1.0000\n",
      "Epoch 37/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0700 - accuracy: 0.9915 - val_loss: 0.2307 - val_accuracy: 1.0000\n",
      "Epoch 38/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 1.0000\n",
      "Epoch 39/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0706 - accuracy: 0.9872 - val_loss: 0.2717 - val_accuracy: 1.0000\n",
      "Epoch 40/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0654 - accuracy: 0.9957 - val_loss: 0.2544 - val_accuracy: 1.0000\n",
      "Epoch 41/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0517 - accuracy: 0.9957 - val_loss: 0.2292 - val_accuracy: 1.0000\n",
      "Epoch 42/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 1.0000\n",
      "Epoch 43/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0546 - accuracy: 0.9957 - val_loss: 0.1796 - val_accuracy: 1.0000\n",
      "Epoch 44/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0527 - accuracy: 0.9957 - val_loss: 0.1563 - val_accuracy: 1.0000\n",
      "Epoch 45/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0477 - accuracy: 0.9957 - val_loss: 0.1534 - val_accuracy: 1.0000\n",
      "Epoch 46/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0494 - accuracy: 0.9957 - val_loss: 0.1723 - val_accuracy: 1.0000\n",
      "Epoch 47/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 1.0000\n",
      "Epoch 48/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 1.0000\n",
      "Epoch 49/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 1.0000\n",
      "Epoch 50/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0453 - accuracy: 0.9957 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 51/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 1.0000\n",
      "Epoch 52/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0346 - accuracy: 0.9957 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
      "Epoch 53/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 1.0000\n",
      "Epoch 54/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 1.0000\n",
      "Epoch 55/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 1.0000\n",
      "Epoch 56/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 1.0000\n",
      "Epoch 57/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 1.0000\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0270 - accuracy: 0.9957 - val_loss: 0.1190 - val_accuracy: 1.0000\n",
      "Epoch 59/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 60/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 1.0000\n",
      "Epoch 61/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 62/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 63/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
      "Epoch 64/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 65/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 66/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 67/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 68/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
      "Epoch 69/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
      "Epoch 70/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 1.0000\n",
      "Epoch 71/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 72/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
      "Epoch 73/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 1.0000\n",
      "Epoch 74/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 1.0000\n",
      "Epoch 75/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 1.0000\n",
      "Epoch 76/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 77/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
      "Epoch 78/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
      "Epoch 79/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 80/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 81/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
      "Epoch 82/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 83/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
      "Epoch 84/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 85/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
      "Epoch 86/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 87/1500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
      "Epoch 88/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
      "Epoch 89/1500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
      "Epoch 90/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 1.0000\n",
      "Epoch 91/1500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 1.0000\n",
      "Epoch 92/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 93/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 1.0000\n",
      "Epoch 94/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 1.0000\n",
      "Epoch 95/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 96/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
      "Epoch 97/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 98/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
      "Epoch 99/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 100/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
      "Epoch 101/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 102/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 103/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
      "Epoch 104/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 105/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 106/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 107/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 108/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 109/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
      "Epoch 110/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 111/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 112/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
      "Epoch 113/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 114/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
      "Epoch 115/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 117/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 118/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 119/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 120/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 121/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 122/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 123/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 124/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 125/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0090 - accuracy: 0.9957 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 126/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 127/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 128/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 129/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 130/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 131/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 132/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 133/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 134/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 135/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 136/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 137/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
      "Epoch 138/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 139/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 140/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 141/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 142/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 143/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 144/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 145/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 146/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 147/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 148/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 149/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 150/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 151/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 0.9957 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 152/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 153/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
      "Epoch 154/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
      "Epoch 155/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 156/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 157/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 158/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 159/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 160/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 161/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 162/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 163/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 164/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 165/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 166/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 167/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 168/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 169/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 170/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 171/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 172/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 173/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
      "Epoch 174/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 175/1500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 176/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 177/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 178/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 179/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 180/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 181/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 182/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 183/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 184/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 185/1500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 186/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 187/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 188/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 189/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 190/1500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 191/1500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 192/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 193/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 194/1500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 195/1500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 196/1500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-b9abe3d3a2c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 1500\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "986dac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1ed1634c970>, 15)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def vec_int(vec):\n",
    "    return np.argmax(vec)\n",
    "im = x_train[np.random.randint(0, len(x_train))]\n",
    "vec = model(im[tf.newaxis,:])\n",
    "plt.imshow(im), vec_int(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad6039ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: score_classifier\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('score_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff42568",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "757e376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a786f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
