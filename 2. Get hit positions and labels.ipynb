{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1326,
   "id": "387bce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor, ceil\n",
    "import json\n",
    "FPS = 25\n",
    "CLIP_LEN = 125#\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "def score(img):\n",
    "    grey = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    thr = cv.threshold(grey, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "    img = thr[tf.newaxis, :,:, tf.newaxis]\n",
    "    return int(np.argmax(model(img)))\n",
    "\n",
    "model = keras.models.load_model('score_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6616daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     \"abT8l2NV9Bk\": {\n",
    "#         \"annotations\": {\n",
    "#             \"label\": \"pulling espresso shot\",\n",
    "#             \"segment\": [\n",
    "#                 126.0,\n",
    "#                 136.0\n",
    "#             ]\n",
    "#         },\n",
    "#         \"duration\": 10.0,\n",
    "#         \"subset\": \"validate\",\n",
    "#         \"url\": \"https://www.youtube.com/watch?v=abT8l2NV9Bk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f785c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v= f'precut/{os.listdir(\"precut\")[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "id": "36522d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "OT_L = [337,348, 234,250]\n",
    "OT_R =  [337,348, 390,406]\n",
    "score_R = [330,334, 380,500]\n",
    "score_L = [330,334, 140,260]\n",
    "\n",
    "num_left = [310,325, 265,285]\n",
    "num_right = [310,325, 355,375]\n",
    "\n",
    "green_box = cv.imread(\"greenbox.png\")\n",
    "red_box = cv.imread(\"redbox.png\")\n",
    "white_box = cv.imread(\"whitebox.png\")\n",
    "\n",
    "\n",
    "\n",
    "def left(frame):\n",
    "    if (np.sum(abs(frame[score_L[0]:score_L[1], score_L[2]:score_L[3]].astype(int)-red_box.astype(int))) <= 40000):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def right(frame):\n",
    "    if (np.sum(abs(frame[score_R[0]:score_R[1], score_R[2]:score_R[3]].astype(int)-green_box.astype(int))) <= 40000):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_for_score(frame):\n",
    "    if left(frame) and right(frame):\n",
    "        return 'both'\n",
    "    elif left(frame) or right(frame):\n",
    "        return 'one'\n",
    "    else:\n",
    "        return 'neither'\n",
    "    \n",
    "def go_to_start_of_light(cap, frame):\n",
    "    '''\n",
    "    Because we are skipping 10 frames at a time, we need to jump back to when the light first came on\n",
    "    '''\n",
    "    while check_for_score(frame) != 'neither':\n",
    "        current_frame = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "        cap.set(cv.CAP_PROP_POS_FRAMES,current_frame-2)\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "def jump_to_blockout_time(cap):\n",
    "    current_frame = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES,current_frame+20)\n",
    "    ret, frame = cap.read()\n",
    "    return frame\n",
    "\n",
    "def jump_past_hit(cap):\n",
    "    current_frame = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES,current_frame+200)\n",
    "    ret, frame = cap.read()\n",
    "    return frame\n",
    "\n",
    "def label(old_frame, current_frame):\n",
    "    left_current = score(current_frame[num_left[0]:num_left[1], num_left[2]:num_left[3]])\n",
    "    right_current  = score(current_frame[num_right[0]:num_right[1], num_right[2]:num_right[3]])\n",
    "    left_old = score(old_frame[num_left[0]:num_left[1], num_left[2]:num_left[3]])\n",
    "    right_old  = score(old_frame[num_right[0]:num_right[1], num_right[2]:num_right[3]])\n",
    "    \n",
    "    if left_current-left_old == 1 and right_current-right_old == 0:\n",
    "        return 'left'\n",
    "    elif right_current-right_old == 1 and left_current-left_old == 0:\n",
    "        return 'right'\n",
    "    elif right_current-right_old == 0 and left_current-left_old == 0:\n",
    "        return 'together'\n",
    "    else:\n",
    "        return None # unclear what it is, pop the clip later\n",
    "    \n",
    "def not_0_or_15(frame):\n",
    "    '''\n",
    "    Avoids catching the weapons test at the beginning or random shit in longer videos\n",
    "    '''\n",
    "    if score(frame[num_left[0]:num_left[1], num_left[2]:num_left[3]]) == 0 and score(frame[num_right[0]:num_right[1], num_right[2]:num_right[3]]) == 0:\n",
    "        return False\n",
    "    elif score(frame[num_left[0]:num_left[1], num_left[2]:num_left[3]]) == 15 or score(frame[num_right[0]:num_right[1], num_right[2]:num_right[3]]) == 15:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def maybe_label_last(clips, frame):\n",
    "    if len(clips) > 0:\n",
    "        if clips[-1].label == None:\n",
    "            clips[-1].label = label(clips[-1].final_img, frame)\n",
    "            print(clips[-1].label)\n",
    "\n",
    "class clip:\n",
    "#     vid_id: str,\n",
    "#     label: str,\n",
    "#     start: float,\n",
    "#     end: float,\n",
    "#     start_frame: int,\n",
    "#     end_frame: int,\n",
    "        \n",
    "    def __init__(self, vid_id, end_frame, final_img = None, label=None):\n",
    "        self.vid_id = vid_id\n",
    "        self.end_frame = end_frame\n",
    "        if final_img is not None:\n",
    "            self.final_img = final_img\n",
    "        self.label = label\n",
    "        \n",
    "\n",
    "def store_clip(video_id, last_frame_idx, frame, clips):\n",
    "    if len(clips) > 0:\n",
    "        if clips[-1].label == None:\n",
    "            print('No label, discarding')\n",
    "            clips.pop() # we never managed to get a label for it\n",
    "    clips.append(clip(video_id, last_frame_idx, frame))\n",
    "    \n",
    "\n",
    "# This is going to be a little tricky\n",
    "\n",
    "# Basically, whenever we detect a light, record the score, then the blockout time to see whether the other person also hit is 25ms, so we have to jump\n",
    "# ahead 7 frames, but lets make it 10 to be safe. \n",
    "# if that is both, then record the time up till then and hold onto this clip\n",
    "# at the next light check to see if the score has increased, if so, label the prev\n",
    "\n",
    "def label_video(vid_id):\n",
    "    v= f'precut/{vid_id}'\n",
    "    if os.path.exists(f'per_vid_labels/{vid_id.replace(\".mp4\", \"\")}'):\n",
    "        print(\"Already have labels\")\n",
    "    else:\n",
    "        cap = cv.VideoCapture(v)\n",
    "        cap.set(cv.CAP_PROP_POS_FRAMES,1000)\n",
    "        clips = []\n",
    "\n",
    "        while cap.isOpened():\n",
    "            current_frame = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES,current_frame+10) # jump 10 frames at a time\n",
    "            ret, frame = cap.read()\n",
    "            # if frame is read correctly ret is True\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "                break\n",
    "\n",
    "            cv.imshow('frame', frame)\n",
    "            if check_for_score(frame) != 'neither':\n",
    "\n",
    "                # label the last clip now we've got a new light\n",
    "                maybe_label_last(clips, frame)\n",
    "\n",
    "                current_frame = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "                # jump ahead by the blockout time when we see a light, to ensure we see both lights if they are on\n",
    "                frame = jump_to_blockout_time(cap)\n",
    "\n",
    "                # if both lights are on, store the clip\n",
    "                if check_for_score(frame) == 'both' and not_0_or_15(frame): # then its a hit which required disambiguation\n",
    "                    # as we may be a few frames in, go to the beginnging, then jump forward to the blockout time precisely\n",
    "                    go_to_start_of_light(cap, frame)\n",
    "                    # jump ahead by the blockout time when we see a light, to ensure we get both\n",
    "                    frame = jump_to_blockout_time(cap)\n",
    "                    store_clip(vid_id, cap.get(cv.CAP_PROP_POS_FRAMES), frame, clips)\n",
    "                    # skip the part where both are on\n",
    "                    frame = jump_past_hit(cap)\n",
    "                elif check_for_score(frame) == 'one':\n",
    "                    pass #\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "            if cv.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        save_json(clips)\n",
    "        return clips\n",
    "\n",
    "\n",
    "def save_json(clips):\n",
    "    json_out = {}\n",
    "\n",
    "    for i,c in enumerate(clips):\n",
    "        if c.label != None:\n",
    "            start, end = c.end_frame-CLIP_LEN, c.end_frame\n",
    "            start_time, end_time = start/FPS, end/FPS\n",
    "            start_floor, end_ceil = float(floor(start_time)), float(ceil(end_time))\n",
    "            c.vid_id = c.vid_id.replace(\".mp4\", \"\")\n",
    "            json_out[f\"{c.vid_id}_{i}\"] = {\n",
    "                    \"annotations\": {\"label\":f\"{c.label}\", \"segment\": [start_time, end_time]},\n",
    "                    \"annotations_frame\":  {\"label\":f\"{c.label}\", \"segment\": [start, end]},\n",
    "                    \"annotations_rounded\": {\"label\":f\"{c.label}\", \"segment\": [start_floor, end_ceil]},\n",
    "                    \"duration\": end_time-start_time,\n",
    "                    \"duration_frame\":end-start,\n",
    "                    \"duration_rounded\": end_ceil-start_floor,\n",
    "                    \"subset\": \"train\",\n",
    "                    \"url\": f'https://www.youtube.com/watch?v={c.vid_id}'\n",
    "            }\n",
    "            \n",
    "    with open(f'per_vid_labels/{c.vid_id.replace(\".mp4\", \"\")}.json', 'w') as outfile:\n",
    "        json.dump(json_out, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "id": "cdf636ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "together\n",
      "left\n",
      "right\n",
      "left\n",
      "left\n",
      "together\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "left\n",
      "left\n",
      "left\n",
      "right\n",
      "left\n",
      "left\n",
      "left\n",
      "together\n",
      "right\n",
      "together\n",
      "together\n",
      "right\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "right\n",
      "together\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "right\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "together\n",
      "together\n",
      "right\n",
      "together\n",
      "left\n",
      "right\n",
      "left\n",
      "together\n",
      "right\n",
      "right\n",
      "left\n",
      "together\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "left\n",
      "left\n",
      "together\n",
      "left\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "left\n",
      "left\n",
      "left\n",
      "together\n",
      "together\n",
      "together\n",
      "left\n",
      "left\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "right\n",
      "left\n",
      "together\n",
      "right\n",
      "right\n",
      "together\n",
      "together\n",
      "right\n",
      "right\n",
      "left\n",
      "together\n",
      "together\n",
      "left\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "left\n",
      "right\n",
      "right\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "left\n",
      "left\n",
      "right\n",
      "left\n",
      "together\n",
      "left\n",
      "right\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "right\n",
      "right\n",
      "right\n",
      "together\n",
      "right\n",
      "together\n",
      "right\n",
      "together\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "together\n",
      "right\n",
      "right\n",
      "right\n",
      "together\n",
      "left\n",
      "together\n",
      "together\n",
      "right\n",
      "right\n",
      "right\n",
      "together\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "right\n",
      "right\n",
      "right\n",
      "together\n",
      "right\n",
      "together\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "left\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "together\n",
      "right\n",
      "together\n",
      "together\n",
      "together\n",
      "together\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "together\n",
      "together\n",
      "together\n",
      "left\n",
      "left\n",
      "together\n",
      "left\n",
      "right\n",
      "left\n",
      "together\n",
      "right\n",
      "left\n",
      "left\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "together\n",
      "together\n",
      "right\n",
      "together\n",
      "right\n",
      "together\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "right\n",
      "together\n",
      "together\n",
      "together\n",
      "right\n",
      "left\n",
      "together\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "left\n",
      "right\n",
      "together\n",
      "left\n",
      "together\n",
      "left\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "left\n",
      "left\n",
      "right\n",
      "left\n",
      "right\n",
      "together\n",
      "right\n",
      "together\n",
      "left\n",
      "together\n",
      "right\n",
      "left\n",
      "left\n",
      "together\n",
      "right\n",
      "right\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "right\n",
      "left\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1388-f4ed11aa9ec2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"precut\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"per_vid_labels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"precut\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mclips\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1387-ed9bb08415d3>\u001b[0m in \u001b[0;36mlabel_video\u001b[1;34m(vid_id)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mcurrent_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_frame\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# jump 10 frames at a time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# if frame is read correctly ret is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while len(os.listdir(\"precut\")) > len(os.listdir(\"per_vid_labels\")):\n",
    "    for v in os.listdir(\"precut\"):\n",
    "        clips = label_video(v)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "48a305d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def play_clip(clip, length=100):\n",
    "    print(clip.label)\n",
    "    v= f'precut/{clip.vid_id}'\n",
    "    print(v, clip.end_frame)\n",
    "    cap = cv.VideoCapture(v)\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES,int(clip.end_frame-length))\n",
    "    idx = 0\n",
    "    while cap.isOpened() and idx < length:\n",
    "        ret, frame = cap.read()\n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        cv.imshow('frame', frame)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        idx += 1\n",
    "        time.sleep(0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "aaa124e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "together\n",
      "precut/3Z_ZbOVXO9g.mp4 9383.0\n",
      "together\n",
      "precut/3Z_ZbOVXO9g.mp4 13225.0\n",
      "right\n",
      "precut/3Z_ZbOVXO9g.mp4 15927.0\n",
      "together\n",
      "precut/3Z_ZbOVXO9g.mp4 19462.0\n",
      "left\n",
      "precut/3Z_ZbOVXO9g.mp4 21044.0\n",
      "right\n",
      "precut/3Z_ZbOVXO9g.mp4 22492.0\n",
      "left\n",
      "precut/3Z_ZbOVXO9g.mp4 26668.0\n",
      "together\n",
      "precut/3Z_ZbOVXO9g.mp4 27776.0\n",
      "right\n",
      "precut/3Z_ZbOVXO9g.mp4 28287.0\n",
      "right\n",
      "precut/3Z_ZbOVXO9g.mp4 30328.0\n",
      "left\n",
      "precut/3Z_ZbOVXO9g.mp4 34604.0\n",
      "together\n",
      "precut/3Z_ZbOVXO9g.mp4 35078.0\n"
     ]
    }
   ],
   "source": [
    "f = os.listdir('per_vid_labels')[3]\n",
    "with open(f'per_vid_labels/{f}') as f:\n",
    "    data = json.load(f)\n",
    "    for k,v in data.items():\n",
    "        vid_id = \"\".join(k.rsplit('_',1)[0])+'.mp4'\n",
    "        end_frame = v['annotations_frame']['segment'][1]\n",
    "        label = v['annotations_frame']['label']\n",
    "        play_clip(clip(vid_id, end_frame, label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "id": "e0cdd2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "precut/-bD8qlI-pxs.mp4 2380.0\n",
      "together\n",
      "precut/-bD8qlI-pxs.mp4 11034.0\n",
      "left\n",
      "precut/-bD8qlI-pxs.mp4 13241.0\n",
      "right\n",
      "precut/-bD8qlI-pxs.mp4 24332.0\n",
      "left\n",
      "precut/-bD8qlI-pxs.mp4 30280.0\n",
      "left\n",
      "precut/-bD8qlI-pxs.mp4 35929.0\n",
      "together\n",
      "precut/-bD8qlI-pxs.mp4 39258.0\n"
     ]
    }
   ],
   "source": [
    "for c in clips:\n",
    "    play_clip(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
